{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5b4528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T07:41:36.735150Z",
     "iopub.status.busy": "2025-08-27T07:41:36.734577Z",
     "iopub.status.idle": "2025-08-27T07:41:37.107490Z",
     "shell.execute_reply": "2025-08-27T07:41:37.106164Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic training data for carbon stock estimation\n",
    "def generate_carbon_stock_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    Generate realistic synthetic data for carbon stock estimation\n",
    "    \n",
    "    Parameters:\n",
    "    n_samples: Number of samples to generate\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with features and target variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate base features with realistic ranges\n",
    "    # NDVI typically ranges from -1 to 1, but for vegetation it's usually 0.1 to 0.9\n",
    "    ndvi_base = np.random.beta(2, 2, n_samples) * 0.8 + 0.1  # Range: 0.1 to 0.9\n",
    "    \n",
    "    # Canopy cover percentage (0 to 100%)\n",
    "    canopy_base = np.random.beta(1.5, 1.5, n_samples) * 100\n",
    "    \n",
    "    # Soil carbon content (typically 0.5% to 8% organic carbon)\n",
    "    soil_carbon_base = np.random.gamma(2, 1.5, n_samples) + 0.5\n",
    "    soil_carbon_base = np.clip(soil_carbon_base, 0.5, 8.0)\n",
    "    \n",
    "    # Add realistic correlations between variables\n",
    "    # Higher NDVI typically correlates with higher canopy cover\n",
    "    correlation_noise = np.random.normal(0, 0.1, n_samples)\n",
    "    canopy_cover = canopy_base * (0.7 + 0.3 * ndvi_base) + correlation_noise * 10\n",
    "    canopy_cover = np.clip(canopy_cover, 0, 100)\n",
    "    \n",
    "    # Soil carbon often correlates with vegetation health\n",
    "    soil_carbon = soil_carbon_base * (0.8 + 0.2 * ndvi_base) + correlation_noise * 0.5\n",
    "    soil_carbon = np.clip(soil_carbon, 0.5, 8.0)\n",
    "    \n",
    "    # NDVI with some noise\n",
    "    ndvi = ndvi_base + correlation_noise * 0.05\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    \n",
    "    # Generate additional environmental factors (for more realistic modeling)\n",
    "    # Elevation (meters above sea level)\n",
    "    elevation = np.random.normal(500, 300, n_samples)\n",
    "    elevation = np.clip(elevation, 0, 3000)\n",
    "    \n",
    "    # Temperature (annual average in Celsius)\n",
    "    temperature = np.random.normal(15, 8, n_samples)\n",
    "    \n",
    "    # Precipitation (annual in mm)\n",
    "    precipitation = np.random.gamma(2, 400, n_samples)\n",
    "    precipitation = np.clip(precipitation, 200, 3000)\n",
    "    \n",
    "    # Calculate carbon sequestration based on realistic relationships\n",
    "    # Formula based on research literature combining multiple factors\n",
    "    \n",
    "    # Base carbon sequestration influenced by vegetation indices\n",
    "    vegetation_factor = (ndvi * 50) + (canopy_cover * 0.3)  # Strong vegetation influence\n",
    "    \n",
    "    # Soil carbon contribution\n",
    "    soil_factor = soil_carbon * 8  # Soil carbon is major contributor\n",
    "    \n",
    "    # Environmental modifiers\n",
    "    temp_modifier = 1 + 0.02 * (temperature - 15)  # Temperature effect\n",
    "    precip_modifier = 1 + 0.0002 * (precipitation - 1000)  # Precipitation effect\n",
    "    elevation_modifier = 1 - 0.0001 * elevation  # Slight elevation effect\n",
    "    \n",
    "    # Combine all factors with realistic coefficients\n",
    "    carbon_sequestration = (\n",
    "        vegetation_factor * 0.4 +  # 40% from vegetation\n",
    "        soil_factor * 0.5 +        # 50% from soil\n",
    "        5  # Base sequestration\n",
    "    ) * temp_modifier * precip_modifier * elevation_modifier\n",
    "    \n",
    "    # Add realistic noise (measurement uncertainty, spatial variability)\n",
    "    noise = np.random.normal(0, carbon_sequestration * 0.15)  # 15% coefficient of variation\n",
    "    carbon_sequestration += noise\n",
    "    \n",
    "    # Ensure realistic range (0 to 150 tCO2e/ha is typical)\n",
    "    carbon_sequestration = np.clip(carbon_sequestration, 0, 150)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'NDVI': ndvi,\n",
    "        'Canopy_Cover_Percent': canopy_cover,\n",
    "        'Soil_Carbon_Percent': soil_carbon,\n",
    "        'Elevation_m': elevation,\n",
    "        'Temperature_C': temperature,\n",
    "        'Precipitation_mm': precipitation,\n",
    "        'Carbon_Sequestration_tCO2e_ha': carbon_sequestration\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating synthetic carbon stock estimation dataset...\")\n",
    "df = generate_carbon_stock_data(n_samples=5000)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3de6bc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T07:42:19.260499Z",
     "iopub.status.busy": "2025-08-27T07:42:19.259687Z",
     "iopub.status.idle": "2025-08-27T07:44:38.813443Z",
     "shell.execute_reply": "2025-08-27T07:44:38.811963Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 00:42:19.848 | INFO     | metagpt.const:get_metagpt_root:33 - PROJECT_ROOT set from environment variable to /\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m terminal\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install --upgrade pandas numpy scikit-learn matplotlib seaborn joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "terminal = Terminal()\n",
    "await terminal.run('pip install --upgrade pandas numpy scikit-learn matplotlib seaborn joblib')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic training data for carbon stock estimation\n",
    "def generate_carbon_stock_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    Generate realistic synthetic data for carbon stock estimation\n",
    "    \n",
    "    Parameters:\n",
    "    n_samples: Number of samples to generate\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with features and target variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate base features with realistic ranges\n",
    "    # NDVI typically ranges from -1 to 1, but for vegetation it's usually 0.1 to 0.9\n",
    "    ndvi_base = np.random.beta(2, 2, n_samples) * 0.8 + 0.1  # Range: 0.1 to 0.9\n",
    "    \n",
    "    # Canopy cover percentage (0 to 100%)\n",
    "    canopy_base = np.random.beta(1.5, 1.5, n_samples) * 100\n",
    "    \n",
    "    # Soil carbon content (typically 0.5% to 8% organic carbon)\n",
    "    soil_carbon_base = np.random.gamma(2, 1.5, n_samples) + 0.5\n",
    "    soil_carbon_base = np.clip(soil_carbon_base, 0.5, 8.0)\n",
    "    \n",
    "    # Add realistic correlations between variables\n",
    "    # Higher NDVI typically correlates with higher canopy cover\n",
    "    correlation_noise = np.random.normal(0, 0.1, n_samples)\n",
    "    canopy_cover = canopy_base * (0.7 + 0.3 * ndvi_base) + correlation_noise * 10\n",
    "    canopy_cover = np.clip(canopy_cover, 0, 100)\n",
    "    \n",
    "    # Soil carbon often correlates with vegetation health\n",
    "    soil_carbon = soil_carbon_base * (0.8 + 0.2 * ndvi_base) + correlation_noise * 0.5\n",
    "    soil_carbon = np.clip(soil_carbon, 0.5, 8.0)\n",
    "    \n",
    "    # NDVI with some noise\n",
    "    ndvi = ndvi_base + correlation_noise * 0.05\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    \n",
    "    # Generate additional environmental factors (for more realistic modeling)\n",
    "    # Elevation (meters above sea level)\n",
    "    elevation = np.random.normal(500, 300, n_samples)\n",
    "    elevation = np.clip(elevation, 0, 3000)\n",
    "    \n",
    "    # Temperature (annual average in Celsius)\n",
    "    temperature = np.random.normal(15, 8, n_samples)\n",
    "    \n",
    "    # Precipitation (annual in mm)\n",
    "    precipitation = np.random.gamma(2, 400, n_samples)\n",
    "    precipitation = np.clip(precipitation, 200, 3000)\n",
    "    \n",
    "    # Calculate carbon sequestration based on realistic relationships\n",
    "    # Formula based on research literature combining multiple factors\n",
    "    \n",
    "    # Base carbon sequestration influenced by vegetation indices\n",
    "    vegetation_factor = (ndvi * 50) + (canopy_cover * 0.3)  # Strong vegetation influence\n",
    "    \n",
    "    # Soil carbon contribution\n",
    "    soil_factor = soil_carbon * 8  # Soil carbon is major contributor\n",
    "    \n",
    "    # Environmental modifiers\n",
    "    temp_modifier = 1 + 0.02 * (temperature - 15)  # Temperature effect\n",
    "    precip_modifier = 1 + 0.0002 * (precipitation - 1000)  # Precipitation effect\n",
    "    elevation_modifier = 1 - 0.0001 * elevation  # Slight elevation effect\n",
    "    \n",
    "    # Combine all factors with realistic coefficients\n",
    "    carbon_sequestration = (\n",
    "        vegetation_factor * 0.4 +  # 40% from vegetation\n",
    "        soil_factor * 0.5 +        # 50% from soil\n",
    "        5  # Base sequestration\n",
    "    ) * temp_modifier * precip_modifier * elevation_modifier\n",
    "    \n",
    "    # Add realistic noise (measurement uncertainty, spatial variability)\n",
    "    noise = np.random.normal(0, carbon_sequestration * 0.15)  # 15% coefficient of variation\n",
    "    carbon_sequestration += noise\n",
    "    \n",
    "    # Ensure realistic range (0 to 150 tCO2e/ha is typical)\n",
    "    carbon_sequestration = np.clip(carbon_sequestration, 0, 150)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'NDVI': ndvi,\n",
    "        'Canopy_Cover_Percent': canopy_cover,\n",
    "        'Soil_Carbon_Percent': soil_carbon,\n",
    "        'Elevation_m': elevation,\n",
    "        'Temperature_C': temperature,\n",
    "        'Precipitation_mm': precipitation,\n",
    "        'Carbon_Sequestration_tCO2e_ha': carbon_sequestration\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating synthetic carbon stock estimation dataset...\")\n",
    "df = generate_carbon_stock_data(n_samples=5000)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81367873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T07:45:29.707427Z",
     "iopub.status.busy": "2025-08-27T07:45:29.707048Z",
     "iopub.status.idle": "2025-08-27T07:47:38.921012Z",
     "shell.execute_reply": "2025-08-27T07:47:38.920106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas not available, using numpy arrays instead\n",
      "Seaborn not available, using matplotlib only\n",
      "Scikit-learn not available, will implement basic functionality\n",
      "Generating synthetic carbon stock estimation dataset...\n",
      "\n",
      "Dataset size: 5000 samples\n",
      "\n",
      "Features: ['NDVI', 'Canopy_Cover_Percent', 'Soil_Carbon_Percent', 'Elevation_m', 'Temperature_C', 'Precipitation_mm', 'Carbon_Sequestration_tCO2e_ha']\n",
      "\n",
      "First 5 samples:\n",
      "NDVI: [0.59441193 0.49246481 0.59564566 0.35221039 0.82572169]\n",
      "Canopy_Cover_Percent: [17.71722383 50.78589564 72.46957828 21.03880765 49.40648103]\n",
      "Soil_Carbon_Percent: [2.2849587  2.04223721 5.37630528 1.79620843 7.75230956]\n",
      "Elevation_m: [461.68091287 279.67126847 314.72213457 318.04958895   0.        ]\n",
      "Temperature_C: [ 8.76726682 11.0455822  22.32536447 13.73400516  9.02010654]\n",
      "Precipitation_mm: [ 653.9033301  1273.53814557  749.0850644  1173.23712437  200.        ]\n",
      "Carbon_Sequestration_tCO2e_ha: [25.67114456 33.37812763 45.24962012 26.88082773 44.83206878]\n",
      "\n",
      "Basic statistics for each feature:\n",
      "NDVI: mean=0.506, std=0.177, min=0.101, max=0.897\n",
      "Canopy_Cover_Percent: mean=42.516, std=21.617, min=0.000, max=95.730\n",
      "Soil_Carbon_Percent: mean=3.101, std=1.746, min=0.500, max=7.802\n",
      "Elevation_m: mean=513.530, std=293.341, min=0.000, max=1521.693\n",
      "Temperature_C: mean=14.881, std=8.080, min=-13.255, max=42.551\n",
      "Precipitation_mm: mean=805.964, std=547.054, min=200.000, max=3000.000\n",
      "Carbon_Sequestration_tCO2e_ha: mean=29.694, std=11.310, min=6.474, max=95.170\n",
      "\n",
      "Dataset generated successfully!\n",
      "\n",
      "Saving dataset to /workspace directory...\n",
      "Dataset saved as NPZ file to /workspace/carbon_stock_dataset.npz\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "terminal = Terminal()\n",
    "\n",
    "# Try multiple installation approaches\n",
    "try:\n",
    "    await terminal.run('pip uninstall -y pandas numpy scikit-learn matplotlib seaborn')\n",
    "    await terminal.run('pip install pandas==1.5.3 numpy==1.24.3 scikit-learn matplotlib seaborn joblib')\n",
    "except:\n",
    "    try:\n",
    "        await terminal.run('conda install -y pandas numpy scikit-learn matplotlib seaborn joblib -c conda-forge')\n",
    "    except:\n",
    "        await terminal.run('pip install --no-cache-dir --force-reinstall pandas numpy scikit-learn matplotlib seaborn joblib')\n",
    "\n",
    "# Import libraries with fallback options\n",
    "try:\n",
    "    import pandas as pd\n",
    "    PANDAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PANDAS_AVAILABLE = False\n",
    "    print(\"Pandas not available, using numpy arrays instead\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError:\n",
    "    print(\"Seaborn not available, using matplotlib only\")\n",
    "\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    import joblib\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"Scikit-learn not available, will implement basic functionality\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic training data for carbon stock estimation\n",
    "def generate_carbon_stock_data(n_samples=5000):\n",
    "    \"\"\"\n",
    "    Generate realistic synthetic data for carbon stock estimation\n",
    "    \n",
    "    Parameters:\n",
    "    n_samples: Number of samples to generate\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary or DataFrame with features and target variable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate base features with realistic ranges\n",
    "    # NDVI typically ranges from -1 to 1, but for vegetation it's usually 0.1 to 0.9\n",
    "    ndvi_base = np.random.beta(2, 2, n_samples) * 0.8 + 0.1  # Range: 0.1 to 0.9\n",
    "    \n",
    "    # Canopy cover percentage (0 to 100%)\n",
    "    canopy_base = np.random.beta(1.5, 1.5, n_samples) * 100\n",
    "    \n",
    "    # Soil carbon content (typically 0.5% to 8% organic carbon)\n",
    "    soil_carbon_base = np.random.gamma(2, 1.5, n_samples) + 0.5\n",
    "    soil_carbon_base = np.clip(soil_carbon_base, 0.5, 8.0)\n",
    "    \n",
    "    # Add realistic correlations between variables\n",
    "    # Higher NDVI typically correlates with higher canopy cover\n",
    "    correlation_noise = np.random.normal(0, 0.1, n_samples)\n",
    "    canopy_cover = canopy_base * (0.7 + 0.3 * ndvi_base) + correlation_noise * 10\n",
    "    canopy_cover = np.clip(canopy_cover, 0, 100)\n",
    "    \n",
    "    # Soil carbon often correlates with vegetation health\n",
    "    soil_carbon = soil_carbon_base * (0.8 + 0.2 * ndvi_base) + correlation_noise * 0.5\n",
    "    soil_carbon = np.clip(soil_carbon, 0.5, 8.0)\n",
    "    \n",
    "    # NDVI with some noise\n",
    "    ndvi = ndvi_base + correlation_noise * 0.05\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    \n",
    "    # Generate additional environmental factors (for more realistic modeling)\n",
    "    # Elevation (meters above sea level)\n",
    "    elevation = np.random.normal(500, 300, n_samples)\n",
    "    elevation = np.clip(elevation, 0, 3000)\n",
    "    \n",
    "    # Temperature (annual average in Celsius)\n",
    "    temperature = np.random.normal(15, 8, n_samples)\n",
    "    \n",
    "    # Precipitation (annual in mm)\n",
    "    precipitation = np.random.gamma(2, 400, n_samples)\n",
    "    precipitation = np.clip(precipitation, 200, 3000)\n",
    "    \n",
    "    # Calculate carbon sequestration based on realistic relationships\n",
    "    # Formula based on research literature combining multiple factors\n",
    "    \n",
    "    # Base carbon sequestration influenced by vegetation indices\n",
    "    vegetation_factor = (ndvi * 50) + (canopy_cover * 0.3)  # Strong vegetation influence\n",
    "    \n",
    "    # Soil carbon contribution\n",
    "    soil_factor = soil_carbon * 8  # Soil carbon is major contributor\n",
    "    \n",
    "    # Environmental modifiers\n",
    "    temp_modifier = 1 + 0.02 * (temperature - 15)  # Temperature effect\n",
    "    precip_modifier = 1 + 0.0002 * (precipitation - 1000)  # Precipitation effect\n",
    "    elevation_modifier = 1 - 0.0001 * elevation  # Slight elevation effect\n",
    "    \n",
    "    # Combine all factors with realistic coefficients\n",
    "    carbon_sequestration = (\n",
    "        vegetation_factor * 0.4 +  # 40% from vegetation\n",
    "        soil_factor * 0.5 +        # 50% from soil\n",
    "        5  # Base sequestration\n",
    "    ) * temp_modifier * precip_modifier * elevation_modifier\n",
    "    \n",
    "    # Add realistic noise (measurement uncertainty, spatial variability)\n",
    "    noise = np.random.normal(0, carbon_sequestration * 0.15)  # 15% coefficient of variation\n",
    "    carbon_sequestration += noise\n",
    "    \n",
    "    # Ensure realistic range (0 to 150 tCO2e/ha is typical)\n",
    "    carbon_sequestration = np.clip(carbon_sequestration, 0, 150)\n",
    "    \n",
    "    # Create data structure\n",
    "    data = {\n",
    "        'NDVI': ndvi,\n",
    "        'Canopy_Cover_Percent': canopy_cover,\n",
    "        'Soil_Carbon_Percent': soil_carbon,\n",
    "        'Elevation_m': elevation,\n",
    "        'Temperature_C': temperature,\n",
    "        'Precipitation_mm': precipitation,\n",
    "        'Carbon_Sequestration_tCO2e_ha': carbon_sequestration\n",
    "    }\n",
    "    \n",
    "    if PANDAS_AVAILABLE:\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating synthetic carbon stock estimation dataset...\")\n",
    "data = generate_carbon_stock_data(n_samples=5000)\n",
    "\n",
    "if PANDAS_AVAILABLE:\n",
    "    df = data\n",
    "    # Display basic information about the dataset\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"\\nDataset info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nBasic statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Check for any missing values\n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    # Alternative display using numpy arrays\n",
    "    print(f\"\\nDataset size: {len(data['NDVI'])} samples\")\n",
    "    print(f\"\\nFeatures: {list(data.keys())}\")\n",
    "    \n",
    "    print(f\"\\nFirst 5 samples:\")\n",
    "    for key in data.keys():\n",
    "        print(f\"{key}: {data[key][:5]}\")\n",
    "    \n",
    "    print(f\"\\nBasic statistics for each feature:\")\n",
    "    for key, values in data.items():\n",
    "        print(f\"{key}: mean={np.mean(values):.3f}, std={np.std(values):.3f}, min={np.min(values):.3f}, max={np.max(values):.3f}\")\n",
    "\n",
    "print(\"\\nDataset generated successfully!\")\n",
    "\n",
    "# Save data to workspace directory\n",
    "print(\"\\nSaving dataset to /workspace directory...\")\n",
    "try:\n",
    "    import os\n",
    "    os.makedirs('/workspace', exist_ok=True)\n",
    "    \n",
    "    if PANDAS_AVAILABLE:\n",
    "        df.to_csv('/workspace/carbon_stock_dataset.csv', index=False)\n",
    "        print(\"Dataset saved as CSV file to /workspace/carbon_stock_dataset.csv\")\n",
    "    else:\n",
    "        # Save as numpy arrays\n",
    "        np.savez('/workspace/carbon_stock_dataset.npz', **data)\n",
    "        print(\"Dataset saved as NPZ file to /workspace/carbon_stock_dataset.npz\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not save to /workspace: {e}\")\n",
    "    print(\"Dataset is available in memory as 'data' variable\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
